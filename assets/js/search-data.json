{
  
    
        "post0": {
            "title": "Hello Xamarin (And 2021)",
            "content": "Hey there. So I planned to do this, at least not 15 days later into the year. 2020 has been a mess of an year and eventhough, on the surface, the start might not be awesome, I have better hopes and goals for 2021. One of these goals is to write even more in this blog (considering I‚Äôve written, what like 6 posts in 5 months?). We will see how that pans out in the future, but here is one update that I‚Äôd like to share, and the topic you might see future posts on. . So I wanted to write an Android App, for a personal usecase. It‚Äôs not that esoteric and an app already exists for it. Then why write one? Because the app required a purchase to keep working and I had a feeling I can create the same app, without the need of any purchase or ads. Now I don‚Äôt really plan to distribute this app on Google Play Store, so other than my ‚Äúman-hours‚Äù and time spent in creating it, I wouldn‚Äôt be having any kind of monetary investment in this. Since its a personal usecase and the app will be written by me only, I am okay with installing it on my phone. So then came the first hurdle in this journey, how to start and which tech stack to use? . The Options . Now I know, the title kindo spoils my end choice, but I‚Äôll still like to share why I choose Xamarin. Since I know nothing about app development and not really good at UI development as well, I wanted an easy entry point for my first ever Android App. (Yes, I‚Äôve gotten around doing my Bachelors and Masters without writing a single Android app üòã). I knew a fair amount of JavaScript and TypeScript, but I am not good at UI development, so I skipped React-Native, eventhough it being one of my primary choices (since the library code I wanted to write could be written in JS/TS easily) and I didnt wanna learn, yet another JS framework, so skipped Ionic and Cordova as well. I didn‚Äôt want to learn yet another language as well, since currently my focus has been on how to write good and maintainable code in the languages I know, so eventhough being similar to JavaScript, I skipped Dart &amp; Flutter. I skipped Kotlin, and all the other native Android stuff Google provides, alongwith Android Studio, primarily because Android Studio is very resource intensive and might just kill my laptop. Plus again, I didn‚Äôt wanna learn another language (Kotlin). . If you‚Äôve been following the blog, you might have noticed that I have been working in C# from some time. I remembered Microsoft creating Xamarin for cross platform app development. Hence I chose Xamarin. I already have Visual Studio on my laptop, I need to practice writing better C# code anyways. Plus I wanted to do all the processing required for this app on-device and not rely on some web service (since they can add/create costs), I thought it would be a good experience in writing that code in C# and learn how to do ‚Äúmore‚Äù using C#. Hence I chose Xamarin as my tool (or framework?) of choice. . Where I am learning Xamarin from? . So I had heard about Xamarin University when I first read about Xamarin. But then I saw that it got closed and some of its content was available on YouTube and their public GitHub repo which is archived. Now I didn‚Äôt have much time to go through various public repos and old videos, plus I prefer reading + doing a tad bit more for learning. So I went to the place where Xamarin University went, Microsoft Learn. I saw two main modules that I feel should give me a good enough intro to Xamarin. First is the module Build Mobile Apps with Xamarin and then I plan to continue with Customize Xamarin Forms App &amp; Advanced Features. Along the way I also plan to read a few books (and if needed watch a video or two). In terms of books, I have two on my radar. First is Xamarin in Action to understand the MVVM pattern and how to write good and testable code. Second is Xamarin Projects to see examples of how to build certain things with Xamarin in action. . On a side note . I know my reasons/issues for choosing Xamarin are weird, and superficial and might not even match to your reasons/issues. Kotlin might be better if you are planning to do full time Android Development, React Native if you already know React and JS well and Dart if you want to learn an awesome new tooling. That being said, do give Xamarin a try. . I‚Äôll definitely keep you, my readers updated with my experience and pitfalls of using Xamarin and C#, and my progress with this app I‚Äôm trying to write. . Do comment if you have suggestions for resources to learn Xamarin, or if you want to share your experience of using Xamarin. Until next time. üòÄ .",
            "url": "https://mitesh1612.github.io/blog/2021/01/16/welcome-xamarin",
            "relUrl": "/2021/01/16/welcome-xamarin",
            "date": " ‚Ä¢ Jan 16, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Blog Update 1",
            "content": "Hey there. It‚Äôs been a long time since I wrote a new post like this one (or tbh any post). I wanted to share an update to my blog. . If you‚Äôve been a reader previously (which is higly unlikely), you may have seen that the blog looks quite different now. I changed my blog tech stack from Gatsby to Fastpages and considered sharing my reasons and experience in the process. Now you can comment on my blog posts, search posts using a search feature and even find posts based on categories. . Choosing the right tech stack . I created the v1 of my blog using Gatsby JS and it resounded to a time where I was learning about JS and React JS. But customizing the blog and adding features like Comments and Search was not trivial using the theme I used and I didn‚Äôt want to change my theme, because it looked wonderful. . Then I tried switching to Hugo, which I felt was a bit more easy to customize and blazingly fast, but again, I had to setup comments and search manually. . Then I saw the release of fastpages by fastai and thought whether this could be a right choice for my blogging needs or not. I loved how they let you setup comments using a simple config changes, has search and categorization using tags built in. It serves all my syntax highlighting and adding LaTeX Math Equations to my blog needs, lets me share Jupyter notebooks as blog posts and sets up CI quite easily. I tried it for my blog and I loved the experience, so I changed the tech stack for my blog, and while I am not completely okay with how few things work in fastpages, it serves my basic blogging needs quite well. I will share the issues that I encounter with Fastpages in this post and be on the lookout for a future post on how to create your own blog using Fastpages . My Issues with Fastpages . While I love fastpages in terms of the features it provides, here are some issues I have with it. Do note that these are a bit subjective and might not be completely relevant to you, but here it is: . The Jekyll Stack and Developer Experience is not fun. Fastpages uses Jekyll to generate this site and I do not know that or Ruby yet. Plus to locally run this blog, I need docker etc in my system, which although not a big deal, its one I‚Äôd like to avoid, vs a single executable for Hugo or a npm CLI tool in case of Gatsby. | Theme customization options are limited. Again I feel this is something I endure more since I don‚Äôt know Jekyll, but if you want your blog to look unique or want to change the whole look as easy as flipping to a different theme, it‚Äôs not possible, until you know how to tinker with Jekyll and custom css files. | Referencing images. I had to change my image references from [Alt Text](Image-Location) to ![](/blog/images/Image-Location). Gatsby had a separate image folder for each posts versus fast pages having a single location for all the images. I will try to fix this issue if possible though. | All these issues aside, Fastpages is a great way to setup a blog easily with most of features one might need, and you should definitely consider it to set up a statically generated blog hosted on GitHub pages. Do try it out and share your experiences in the comments below. .",
            "url": "https://mitesh1612.github.io/blog/2020/12/24/blog-update-1",
            "relUrl": "/2020/12/24/blog-update-1",
            "date": " ‚Ä¢ Dec 24, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "The different kinds of Unit Tests",
            "content": "In my previous post, I talked about various kinds of Tests. As a developer working for a mature codebase, the most common tests that you will need to write are Unit Tests, and its a good practice tbh. . While working on my team‚Äôs project (which was in a fairly early stage), I saw various kinds of Unit Tests and researched a bit myself on how to write some good UTs. Today I plan to share the same in this post. I‚Äôll talk about various types of Unit Tests and when you might want to use each. . A quick disclaimer here. Since I work on a C# project, and have the most experience in writing C# (or Python tests), my examples are in C# with NUnit. But language or testing frameworks are subjective and there is no one size fits all. My main goal here is to capture these patterns so that you can use them in your own exploits of writing Unit Tests. . Example Scenario . While this may get refuted later, lets have an example scenario. Consider we have a code for which we want to write a Unit Test. This code takes a User Name and Password, and assuming they are valid, generates an access token for the user and stores it in a cookie. Here is some example code for the same: . public class SignInUser : ISiteActions { public SignInUser(ICookierHelper cookieHelper, ITokenGenerator tokenGenerator, IDataProvider userDataProvider, IPasswordHasher hasher) { this.cookieHelper = cookieHelper; this.tokenGenerator = tokenGenerator; this.userDataProvider = userDataProvider; this.passwordHasher = passwordHasher; } public bool Execute(string username, string password) { var user = this.userDataProvider.getUser(username); if (user == null) return false; if(!this.passwordHasher.DoesMatch(password, user.salt, user.hash)) return false; var accessToken = this.tokenGenerator.Encode(username, user.userId); this.cookieHelper.setCookie(Constants.CookieName, accessToken); } } . Again this is just to set some context. These patterns can be easily applied to any kind of code we are testing. . Arrange-Act-Assert . This is the de-facto, canonical version of the Unit Test. This basically describes the structure of a Unit Test. Unit Tests usually test a single piece of code (say a public class method) and check whether one effect (or output of that method) was correct. Depending upon the complexity of the code being tested, some setup might be necessary, before the code under test can be executed. This pattern of setting up proper conditions for a test, running the code under test and then verifying the result is called arrange-act-assert pattern. For example, say we want to test the Execute method for the above code with a valid user name but invalid password, here is how we might write it. . public class SignInUserTests : SiteTestFrameworkBase { [Test] public void ShouldFailFor_InvalidPassword() { // Arrange var userSignIn = new SignInUser(GetMock&lt;ICookieHelper&gt;(), GetMock&lt;ITokenGenerator&gt;(), GetMock&lt;IDataProvider&gt;(), GetMock&lt;IPasswordHasher&gt;()); var username = this.GetValidUserName(); var password = this.MakePasswordDirty(username); // Act var result = userSignIn.Execute(username, password); // Assert Assert.IsFalse(result); } } . In this over simplified code, we are using Mock Dependencies to create an instance of the SignInUser class. We are also getting a valid username and getting an invalid password for that user. This all setup is part of Arrange. After that, we test the method in our Act section by passing our inputs and then validate the output in Assert section. . This code is an example of a strong Arrange-Act-Assert Pattern. This pattern is great when a specific situation is being tested or a set of specific inputs are tested. It is also great when you want to verify a single thing about the execution of your code. . But what happens when there are multiple side-effects of your code, your code doing multiple things? . One Act, Many Assertions . Sometimes, while testing some code, the code might have multiple side effects and we might want to make multiple assertions about these multiples effects that the code had. This seems simple, instead of having one assert, we can have multiple asserts in the end of our test. Many people are opposed to this, and while not being a strong problem, it might become a smell in your code. . Why are multiple assertions a smell? . Consider the case where your test code has multiple assertions in the end. One of the problems with this is that when a test fails, we might need to determine what part of code has failed. In this case, we might need to resort to going through stack traces to find out what actually failed. . Also, in NUnit (and a lot of other testing frameworks) the failure of a single assertion might cause the test execution to stop, so an early failure in this test can mask probable future failures in the test. . There is a solution to this problem, by using a method called specification testing or behavior driven development testing. Specification based testing techniques uses the specification of the program as the point of reference for test data selection. . For example, for the above code, we might want to test when a user successfully logs in, that result comes out true and the respective cookie is set. Consider the following code: . public class SignInUserTests : SiteTestFrameworkBase { [SetUp] public void SetUp() { var userSignIn = new SignInUser(GetMock&lt;ICookieHelper&gt;(), GetMock&lt;ITokenGenerator&gt;(), GetMock&lt;IDataProvider&gt;(), GetMock&lt;IPasswordHasher&gt;()); var username = this.GetValidUserName(); var password = this.GetValidPassword(username); var result = userSignIn.Execute(username, password); } [Test] public void ShouldSucceed() =&gt; Assert.IsTrue(result); [Test] public void ShouldSetCookie() =&gt; GetMock&lt;ICookieHelper&gt;().VerifyCalled(x =&gt; x.SetCookie(Constants.CookieName, TestConstants.TokenValue)); } . Since the above two results can fail indepedently from each other (we might not be able to set the cookie for some reason, for example), so putting both these assertions in the same test doesn‚Äôt make sense. . This type of test is great when your piece of code has multiple effects that can succeed or fail independently. . Test Cases . I like to call this pattern, Multiple Arranges, to match with the above title, but that‚Äôs probably wrong. This type of test is useful when we want to test a lot of different inputs matched with a lot of different outputs. Here we can do away with our example since it won‚Äôt be really helpful for this type of test. . Assume, we wrote an awesome function ConvertToEmoji that can convert the text description of an emoji to the actual emoji and we want to validate lots of different inputs and validate their outputs. We could write an Arrange-Act-Assert pattern type test for each input but that would have a lot of duplicate code and we want to maintain our test code maintainable. . NUnit has a great feature to write specifically these type of tests that can scale well (stay tuned after the example to know what to do if your test framework doesn‚Äôt have this feature). . This is how this type of test can be written in NUnit. . public class EmojiConverterTests { [TestCase(&quot;smile&quot;, &quot;üòÄ&quot;)] [TestCase(&quot;poop&quot;, &quot;üí©&quot;)] [TestCase(&quot;cry&quot;, &quot;üò™&quot;)] [TestCase(&quot;diamond&quot;, &quot;üíé&quot;)] [TestCase(&quot;ballon&quot;, &quot;üéà&quot;)] [TestCase(&quot;thumbs up&quot;, &quot;üëç&quot;)] [TestCase(&quot;pizza&quot;, &quot;üçï&quot;)] [TestCase(&quot;fire&quot;, &quot;üî•&quot;)] public void ConversionTests(string description, string emoji) { Assert.AreEqual(EmojiConverter.ConvertToEmoji(description), emoji) } } . What if your test library doesn‚Äôt support this? . Say your framework doesn‚Äôt support this type of feature, what can you do? . One way is that maybe you can have some sort of collection to store your input-output pairs and then iterate over the collection. It‚Äôs not quite as slick versus when this is built in the test library but it can still let you remove duplicate code and more importantly, let you add new tests easily. Example Code: . public void ConversionTests() { List&lt;string&gt; inputs = this.GetEmojiInputs(); List&lt;string&gt; outputs = this.GetEmojiOutputs(); for(int i = 0;i&lt;inputs.Count;i++) { Assert.AreEqual(EmojiConverter.ConvertToEmoji(inputs[i]), outputs[i]); } } . These type of tests are quite common for conversion of client contracts of an API to your server models or your server models to your database entity models (having separate models is actually quite a good pattern), where in we test with a valid set of inputs and invalid set of inputs (their number usually depends on the complexity of the objects being converted). Sometimes, we might not be able to pass in values of the test cases directly, then we can probably read the objects from a file system as well. . For example: . public class ClientServerModelsConverterTests { [TestCase(&quot;/inputs/valid1&quot;, &quot;/outputs/valid1&quot;)] [TestCase(&quot;/inputs/valid2&quot;, &quot;/outputs/valid2&quot;)] public void ConversionTests(string inputPath, string outputPath) { var inputObject = ReadFromFilePath&lt;ClientObj&gt;(inputPath); var outputObject = ReadFromFilePath&lt;ServerObj&gt;(outputPath); Assert.IsTrue(ObjectsAreEqual(inputObject.ToServerObject(), outputObject)); } } . (I know this code might have other issues, like how we can convert two inputs to one, but hey if you are nitpicking into my code, that means you read and understood it and mission accomplished üòé) . This pattern also makes it easy to add new test cases. And using NUnit‚Äôs pattern we can easily show that we are testing the conversion process, not just the conversion for one specific input. This lets you explain your intent in test cases quite clearly and that is quite helpful. . What type of test you should use? . As I said, there is no one size fits all and each type of unit test is great in its own context. And when in doubt, the standard arrange-act-assert is a great start! . Also, remember that test is code too. Like production code that will be deployed, we should make testing code more maintainable, avoid duplication and scalable to new cases. . I hope this post and the previous post gives you some ideas to help your test code be even better that it already is. üòÄ . Hope you enjoyed this post. If you just discovered my blog, do try reading some other posts from me. You can always connect with me on my socials to discuss or engage in conversations about software development with me. .",
            "url": "https://mitesh1612.github.io/blog/2020/11/27/different-types-UTs",
            "relUrl": "/2020/11/27/different-types-UTs",
            "date": " ‚Ä¢ Nov 27, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "A Primer on Different Kinds of Tests",
            "content": "I haven‚Äôt been a developer for too long (yet) to justify or even explain the importance of well written tests, especially in your CI system, but over my experience in recent times, I have seen great tests helping me catch a lot of future headaches. That being said, while developing a service end-to-end, I got to see the different kinds of tests and testing strategies and I thought why not ‚Äúblog my journey‚Äù on testing. So buckle up for a fun ride, into the land of testing. . The Importance of Testing . If you are working on a decent codebase, chances are that the codebase has its own CI System, whether using GitHub Actions, Azure DevOps, Travis CI, Circle CI, Jenkins. One of the most important tasks for a CI System is to run tests on your codebase, preferably so that merging your PR doesn‚Äôt break anything. . This is easier said, than done though. Having slow, long running tests in your Pull Request CI Builds slows down the check-in speed for a developer and makes you wait longer to get your changes merged. On the other hand, removing longer tests for something like Continuous Deployment builds puts you in the hazard of losing reliability and the quality signal of the master (or ‚Äúmain‚Äù) branches. Then it becomes a blame game of finding what broke the test and getting it fixed. Surely there must be a better way. . The different kinds of Tests . One of the main concerns for a test suite is the confusion around what each test should cover. Your tests might become too broad when they are expected to be focused or too focused when expected to have a broader testing. Thus, it becomes important to think about the kind of test you are writing while writing it. There are various ways to categorize tests. The famous types of tests are: . Unit Tests | Integration Tests | Acceptance Tests | . Unit Tests . These are small, micro tests, that test a single class or method, in isolation from its dependencies. This part is important. When you isolate the code under test, the tests become more focused and expressive. A test that touches any external resource such as the database (even if it is mock), file system, web service etc. is not a Unit Test. (Or might be? Stay tuned) . The purpose of Unit Tests is to validate that the piece of code under test is functionally correct and giving the proper expected output for a given input. Good Unit Tests also help by providing a documentation on how the class is expected to function for any consumers. . What are good unit tests? . Good Unit Tests are fast, atomic, isolated, conclusive and generally order independent. Usually they are executed automatically by the CI server on each commit to the version control system. . You should be careful about categorizing tests as Unit Tests. Like Code Smells, there are a lot of smells for Unit Tests like too much setup, long test methods, race conditions, lack of CI Integration. If your Unit Tests have these smells, consider a good refactor styled bath for your codebase. . There are a lot of test frameworks for a lot of different languages, like NUnit for C#, pytest for Python etc. which I don‚Äôt plan to cover here, they in general possess pretty good documentation. Although, stay tuned for another post on the various kinds of Unit Tests. . Integration Tests . You use them when your test requires some kind of an external dependency. So these tests includes testing the code that interacts with some external components like a data access layer, web service, file system etc. These tests provide real value when they use the actual real dependency (and not something mock). But due to this, they are harder to setup and slower to write and run than unit tests. That being said, these tests are absolutely necessary to have some kind of confidence in your test suite. . The primary purpose of these tests is to validate the code that work or manipulates an external system, but they also sometimes validate a portion of the remote system. For example if you use a repository pattern for data access and have a test that performs a Save() on a database, this test also in part checks the database connection, database engine, the network connection (if not onprem) etc. These kind of tests exercise a large block of code and infrastructure than unit tests, but that makes more brittle. . What are good integration tests? . Good Integration Tests validate the features of an external system that is used in your application. They do not attempt to cover the full set of functionality. Like Unit Tests, ideally these tests should be atomic, isolated, conclusive and order independent. . Smells for Integration Tests also include too much setup, long test methods, race conditions, lack of continuous integration. . Acceptance Tests . These are the tests that execute your entire stack, maybe not the user interface. Thus there is no usage of any kind of test doubles (mock objects/systems). The primary purpose of these tests is validate things like component wire up, application stack integration, basic use cases, system performance and stability. These tests are usually run the least often as they are time consuming to execute and require extensive setup (like deploying your services). . What are good acceptance tests? . Good acceptance tests can be understood by a user and are written in terms common to business. Their code smells include attempting to validate every path through the system. . There are also the category of UI Tests, but to be honest, I‚Äôm not really experienced much in those to write something meaningful about them, so I‚Äôll be skipping those. . Towards L0,L1,L2 Tests . Until now, all that I wrote seems kindo bookish, something you‚Äôd read in a Software Engineering book. So let me take you on a real tour of how testing is approached. In this wonderful article about DevOps in Microsoft, these guys explain how breaking tests into L0,L1,L2 etc helps them simplify and drastically improve their testing approach. . To hillariously simplify and summarize this article, they divide their tests as L0 and L1 which are still your unit tests and L2 and L3 which are functional/integration/acceptance tests. . Usually, they favour tests with fewest external dependencies and run majority of tests as part of the build process for a commit. If tests aren‚Äôt dependent, we could also run them in parellel, which gives faster CI build times. Although such L0 tests cannot test every aspect of the service, but the main point to not write a (functional) L2/L3 test where a (unit) L0 test could give the same information. . Since L2 and L3 tests are functional tests, they should always work with the public API of the product. . When we shift our focus on more L0 tests than L2/L3 tests, we make design implementations that support testability. . Shift-Left . . This kind of shift left approach lets you finish most of the testing before a change is merged into the master. . The new taxonomy of testing . In this way, tests were divided into the following categories: . L0 Tests: These are the fast, in-memory unit tests, the basic idea of a Unit test to most people as well. These tests depend on the code in the assembly and nothing else. These can be testing your business logic with assertions where given input returns an expected output. | L1 Tests: These are also Unit Tests but might require a Database or File System along with the assembly (can be mock). These dont include deploying the service. The most common tests here are for controller methods. For example say each route of your controller maps to a function, then you test that function (not deploy the controller) in a L1 test. | . # The controller route @route(/:userId) def getUser(userId): return userDb.Find(userId) # The L1 Test # Can set the db context to a mock db def test_getUser(): assert(getUser(1) == user[1]) . (This might not look like an actual test for python code, but I wanted to represent how to test controllers without deploying the service and then calling the service api path) . L2 Tests: These are Functional tests that run against ‚Äútestable‚Äù service deployment. These require deploying the service but you might mock some service dependencies for ease. For example, deploying the service in a test environment and hitting the public API to perform basic use cases | L3 Tests: These tests run against production and need a full product deployment. | . There are some quite good guidelines in the article on how to write good L0 and L2 tests that I strongly insist you to read (Unit Test Characteristics and Making Functional Tests Independent), since I don‚Äôt want to reiterate those same things. . Improving your Test Game . While I did provide 2 different taxonomies for categorizing tests, these are not the only way to categorize them. I tried to cover the various famous categories and share the example of L0, L1, L2 and L3 tests that was tried and tested (üòú) by me. While I might not be super knowledgeable in all the kinds of tests, you can share your experiences and techniques you use to improve your test suites, I‚Äôm open to discussion! üòÅ . If you liked this article, try reading some other articles on this blog. You can always follow me on my socials to connect, discuss with me. .",
            "url": "https://mitesh1612.github.io/blog/2020/10/06/software-testing",
            "relUrl": "/2020/10/06/software-testing",
            "date": " ‚Ä¢ Oct 6, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "The Naivete of Naive Bayes",
            "content": "So I finally figured out how to render LaTeX equations on my blog, and thus I can use my truly ‚Äúuseful‚Äù LaTex knowledge to start a new series on something that truly interests me. Machine Learning and how it works using the relative math in a simpler (and hopefully fun) language, to not scare away people who don‚Äôt prefer maths. Welcome to my series Machine Learning, with the Maths! (It sounds way cooler in my head!) . The point of this series is not to be a substitute for the plethora of tutorials already available on the topic of Machine Learning. I will try to explain the basic concepts behind each machine learning algorithm, and try to implement it from scratch using Python and NumPy. Maybe you can and hopefully will find better resources, but I hope this can be a good start for you. Plus, where else can I use my superbly huge and comically large Latex equations. Let‚Äôs begin, this probably very long post. . I am planning to write an introductory post on Bayes theorem anyways, so I am gonna skip the gory details here and link it in this post when I do end up writing it. Here‚Äôs the short intro to Bayes theorem. . There are a lot of ways to define what Bayes theorem represents. It can be thought of way to ‚Äúreverse‚Äù conditional probabilities. The interpretation we will be going through is that it can be used to find the probability of an event occurring, given the probability of another event that has already occurred. We can use (fun?) letters to denote some events, but hey, this is a Machine Learning post, so lets talk like that. Say you have a hypothesis (or an assumption) and you want to find the probability of that assumption, given the data. That is actually what Bayes theorem gives! Don‚Äôt believe me?. Let‚Äôs look at the equations . . This says that the gives the probability of event E occuring, given some event F occurs. Say event E represents our hypothesis and F represents the probability of obsering the data we observe. Then P(E/F) basically represents how much the data supports our assumption. Hence many times, Bayes theorem is also written like this . . The term P(Hypothesis) is also called prior or prior beliefs. Why prior? It is the degree of the conviction that the hypothesis is true before we observe the actual data. Remember, prior is the sometimes the trickiest terms to determine (as mentioned later here). The term P(Hypothesis/Data) is called the posterior probability, which represents ‚Äúthe possibility of the hypothesis, given the data‚Äù. Posterior is usually build after seeing the data. The term P(Data/Hypothesis) is a fun one. It represents the probability of having obtained the data, given the hypothesis and is called the likelihood term. In that way, P(Data) is the Evidence we have, or the data we have. . The evidence term can be broken as . P(F)=P(F‚à£E)P(E)+P(F‚à£E‚Ä≤)P(E‚Ä≤)P(F) = P(F|E)P(E) + P(F|E&amp;#x27;)P(E&amp;#x27;)P(F)=P(F‚à£E)P(E)+P(F‚à£E‚Ä≤)P(E‚Ä≤) . as well, which might come in handy later. . How Bayes Theorem is relevant to Machine Learning? . What Bayes theorem gives us is a framework to update our beliefs using evidence. Say you have a prior belief that some event occurs. Then you receive some evidence. You weigh your prior using the likelihood of that evidence happening and get a new belief, the posterior! Now when you get some more new evidence, you replace your prior belief with the posterior found about the event, and get a new posterior belief. And hey if you are not a probability nerd, let me explain this to you in a simpler way. Say you are a man who have lived his whole life inside a cave, and never got out. Now once you get out and see the sun rising on the east, what do you believe? Does it always happen or is this a one off? You assign some ‚Äúprior‚Äù probability of the sun rising in the east. The next day, the sun rises in east again and you update your belief using this evidence. Hmm, sun might rise on east on Mondays and Tuesdays and again update your belief (posterior). The more evidence you gather, the more you are sure about an event, and frankly that‚Äôs the crux of Machine Learning as well. We use data, or evidence, to update our beliefs about something. . Now with that out of the way, let‚Äôs turn to the example and actually implement this. . Spam me not! . The most common use of Naive Bayes, is for spam filters. Let‚Äôs look into how we can implement a spam filter using Naive Bayes from scratch. . Sometime ago, there was a scam on twitter where accounts of famous people like Elon Musk, Jeff Bezos etc. were hacked for ‚Äúbitcoin‚Äù scams, and let‚Äôs try to build a spam filter to help the poor souls who actually sent bitcoins to this scam. Let S be the event that the message is spam and B be the event that the message contains the word ‚Äòbitcoin‚Äô. Baye‚Äôs theorem tells us that the conditional probability that the message is spam, given it contains the word bitcoin is: . . The numerator is the probability that a message is spam and contains bitcoin, while the denominator is just the probability that a message contains bitcoin. How? P(B/S)P(S) = P(B,S) using the definition of conditional probablity (on which I did write a fun post you can read here) and the denominator is essentially P(B). In this sense, we can think of this calculation simply representing the proportion of bitcoin messages are spam. . Say we have a large number of messages that we know are spam and a large collection of messages that we know are ham (the word used for not spam commonly). Using that we can easily estimate P(B/S) and P(B/S‚Äô). Let‚Äôs make an assumption that it is equally likely that a message is spam or ham. Then P(S) = P(S‚Äô) = 0.5. Taking out the common term in the above equation, we get . . Now say we find out that 50% of the spam messages contain the word bitcoin but only 1% of non spam messages do, then the probablity that any given bitcoin-containing message is spam is: . 0.5/(0.5 + 0.01) = 98% . Making the Spam Filter more Sophisticated . Let‚Äôs bring in equations now (this aint called Machine Learning with Maths for no reason). Imagine we have a vocabulary of many words w1, w2, ‚Ä¶ ,wn and we say event Xi means the message contains the word wi. Also, since we are imagining so much, imagine that we have some undisclosed process to get an estimate of P(Xi/S) and P(Xi/S‚Äô), or basically the probability that a spam/not spam message contains the ith word. . Why is this Bayes Naive? . The key to Naive Bayes is making the (big) assumption that the presences (or absences) of each word are independent of one another, conditional on a message being spam or not. Intuitively, this assumption means that knowing whether a certain spam message contains the word bitcoin gives you no information about whether that same message contains the word rolex. In terms of ML terminologies, it makes the assumption that features of a measurement are independent of each other. . In math terms, this assumption means that: . . Now I am not going to lie, this is an extreme assumption, and the reason why it is called Naive Bayes. Say our vocabulary contains only the words ‚Äúbitcoin‚Äù and ‚Äúgold‚Äù and that half the messages that are spam are for ‚Äúearn bitcoin‚Äù and the other half messages that are spam are for ‚Äú26kt gold‚Äù. Thus P(Bitcoin/Spam) = 0.5 and P(Gold/Scam) = 0.5 as well. The probability that a message is spam which contains both ‚Äúbitcoin‚Äù and ‚Äúgold‚Äù is P(Bitcoin, Gold/Spam) = P(Bitcoin/Spam) * P(Gold/Spam) = 0.5 x 0.5 = 0.25. This happens since we assumed away the knowledge that ‚Äúbitcoin‚Äù and ‚Äúgold‚Äù never occur together. . The fun part is that, despite the unrealisticness of this assumption, this model often performs well and has historically been used in actual spam filters. . Using the same equation that we used for the bitcoin only spam filter, we can calculate the probability of a message being spam using the following equation: . . The Naive Bayes assumption allows us to compute each of the probabilities on the right simply by multiplying together the individual probability estimates for each vocabulary word and hence simplifies our calculation. . A practical consideration . In order to prevent underflow, where in computers don‚Äôt do well with floating-point numbers that are too close to 0, we try to avoid multiplying probability values. Instead of that, we can use log to multiply probabilities using log(ab) = log(a) + log(b) and then do an exp(logx) = x to get back the actual probability. This doesn‚Äôt change any of the equations or assumptions, it is just a small practical trick to avoid getting weird answers. . Training? . Now the only problem is estimating P(Xi/S) and P(Xi/S‚Äô), the probabilities that a spam message (or nonspam message) contains the word wi. If we have a fair number of ‚Äútraining‚Äù messages labeled as spam and not spam, an obvious first try is to estimate P(Xi/S) simply as the fraction of spam messages containing the word wi. . Being Smooth . While this calculation seems reasonable, it has a huge problem. Say, in our training messages, the word ‚Äúdata‚Äù only occurs in nonspam messages. Then we‚Äôd estimate P(data/S)=0. The result is that our Naive Bayes classifier would always assign spam probability 0 to any message containing the word data, even a message like ‚Äúdata on free bitcoin and 26 kt gold free.‚Äù To avoid this, we usually use some kind of smoothing. One of the simplest ways is to choose a pseudo count k (basically assuming that there are atleast k spam/ham messages containing the given word i). This gives us the following equation for estimating the probability of seeing the ith word in a spam or ham message as follows: . . We can do similarly for P(Xi/S‚Äô) where in we assume we also saw k additional nonspams containing the word and k additional nonspams not containing the word. . For example, if data occurs in 0/98 spam messages, and if k is 1, we estimate P(data/S) as 1/100 = 0.01, which allows our classifier to still assign some nonzero spam probability to messages that contain the word data. . Code Implementation . Now that we have all the pieces to build our classifier, the only thing to do is to actually build our classifier. This post contains code snippets but you can find the code on my GitHub repo here . Since we are planning to deal with text data with this classifier, we will be needing to tokenize our text to words/tokens. We assume we have a simple function tokenize() that returns all the tokens in a sentence. (A simple implementation for this would be to convert all text to lower case and then use regular expressions to remove special characters like apostrophes). We can obviously have complex tokenizing pipelines and more text pre-processings, but we will skip that for now. . Our training data consists of the message and a boolean is_spam indicating whether the message is spam?. We implement our classifier as a class to use it in a better way. The constructor only takes the parameter k. We also initialize a set to contain unique tokens, dictionaries which are counters to track how often each token is seen in spam messages and ham messages, and the counts of how many spam and ham messages it was trained on. . class NaiveBayesClassifier: def __init__(self, k = 0.5): self.k = k self.tokens = set() self.token_spam_counts = defaultdict(int) self.token_ham_counts = defaultdict(int) self.spam_messages = self.ham_messages = 0 . Now to implement the train function for it. According to the message type, we first increment the counts of spam or ham messages. Then we tokenize the message and then increment the spam/ham counts for each token. . def train(self, messages): for message in messages: if message.is_spam: self.spam_messages += 1 else: self.ham_messages += 1 # Increment word counts for token in tokenize(message.text): self.tokens.add(token) if message.is_spam: self.token_spam_counts[token] += 1 else: self.token_ham_counts[token] += 1 . Ultimately we‚Äôll want to predict P(spam / token). As we saw earlier, to apply Bayes‚Äôs theorem we need to know P(token / spam) and P(token / ham) for each token in the vocabulary. So we‚Äôll create a helper function to compute those. (_probabilities) . def _probabilities(self, token): &quot;&quot;&quot; Returns P(token/spam) and P(token/ham) &quot;&quot;&quot; spam = self.token_spam_counts[token] ham = self.token_ham_counts[token] p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k) p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k) return p_token_spam, p_token_ham . Finally we can write a predict method, and we will use the method of summing logs (as mentioned in here). This takes a message and tokenizes it. Then using the helper function it finds the probabilities of each token in the vocabulary. Then adds/multiplies the respective probability of seeing/not seeing the token in te message and then returns the probability of the given message being spam or ham. . def predict(self, text): text_tokens = tokenize(text) log_prob_if_spam = log_prob_if_ham = 0.0 # Iterate through each word in vocabulary for token in self.tokens: prob_if_spam, prob_if_ham = self._probabilities(token) # If token appears in message # add the log probability of seeing it if token in text_tokens: log_prob_if_spam += math.log(prob_if_spam) log_prob_if_ham += math.log(prob_if_ham) # Otherwise add the log probability # of not seeing it which is # log(1-probability of seeing it) else: log_prob_if_spam += math.log(1-prob_if_spam) log_prob_if_ham += math.log(1-prob_if_ham) prob_if_spam = math.exp(log_prob_if_spam) prob_if_ham = math.exp(log_prob_if_ham) . Inspecting the Model . We can even have a helper function that ‚Äúinspect‚Äù the model‚Äôs innards see which words are indicative of spam/not spam. . def p_spam_given_token(token, model): prob_if_spam, prob_if_ham = model._probabilities(token) return prob_if_spam/(prob_if_spam + prob_if_ham) words = sorted(model.tokens, key=lambda t: p_spam_given_token(t,model)) print(&quot;Spammiest Words: &quot;, words[-10:]) print(&quot;Hammiest Words: &quot;, words[:10]) . Trying out the model on a dataset . We will run this model on the UCI ML SMS Spam Dataset which can be found here. For the detailed code, you can visit this notebook in my GitHub repo . The model returns ‚Äúclaim‚Äù ‚Äúprize‚Äù as words indicating the message is spam which is a good sign of this performing okay. . Possible Improvements . How could we get better performance? One obvious way would be to get more data to train on. There are a number of ways to improve the model as well. Here are some possibilities that you might try: . Our classifier takes into account every word that appears in the training set, even words that appear only once. Modify the classifier to accept an optional min_count threshold and ignore tokens that don‚Äôt appear at least that many times. | The tokenizer has no notion of similar words (e.g., cheap and cheapest). Modify the classifier to take an optional stemmer function that converts words to equivalence classes of words. | Although our features are all of the form ‚Äúmessage contains word wi,‚Äù there‚Äôs no reason why this has to be the case. In our implementation, we could add extra features like ‚Äúmessage contains a number‚Äù by creating phony tokens like contains:number and modifying the tokenizer to emit them when appropriate. | . The horrors of prior . After all that code, there is one small topic I would like to touch on, which is on estimating priors. . Prior is one of the trickiest terms to determine in the Bayes equation. As explained really nicely in this video by Veritasium, Bayes theorem tells us how to update our beliefs in light of new evidence. It cant tell us how to set our prior beliefs. So it is possible for someone to have a different prior belief than other, because they are subjective. Some people might be more certain about a prior belief that other people. That‚Äôs how bias can creep in. And we definitely need a world, and a model, with lesser bias. . Mathematically, instead of ‚Äúchoosing‚Äù a prior, we assume the prior probability to follow a prior model and we try to estimate these model parameters (for example assuming the prior distribution follows Gaussian distribution and finding its parameters) . For further exploration . You can visit this blog for another ‚Äúfrom scratch‚Äù implementation of Naive Bayes or this blog as well . . The idea and much of the code was from the book ‚ÄúData Science from Scratch‚Äù which is truly an amazing read for someone who wants to implement stuff from scratch. . If you stuck with me till this long, it seems you enjoyed this post. I hope to keep updating this new Machine Learning, with the Maths series so keep an eye on this blog. You can always @ me at my socials or the GitHub repo for this blog. Thanks for reading. üòä .",
            "url": "https://mitesh1612.github.io/blog/2020/08/30/naive-bayes",
            "relUrl": "/2020/08/30/naive-bayes",
            "date": " ‚Ä¢ Aug 30, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "C# Properties and their different Uses",
            "content": "I learnt C# in parts from various resources, mostly because each one had their different starting points. One book heavily relied on using Visual Studio which definitely makes life easy, but makes you ignore the nitties-gritties of setting up .NET projects, while one did everything from scratch, which did scratch my itch (Get it? üòú) but had a really really slow pace. . One constructs that I learnt about while seeing how to create classes was C# Properties. Properties have a little confusing syntax as described here (in all the non syntax highlighted glory of C#) . public class MyRiches { // Normal Data Members public int Money; // Properties public int GoldInKgs { get; set; } } . If you come from some other language, upon seeing this, you might be like . When I learnt about properties, I kept wondering why do I work extra hard to define data members when I can do it in a simpler and a much known way. I though it was just syntactic sugar, only with its visible diabetes as well. Then I saw an interesting usage of properties in our existing codebase, something like this . public class MyClass { public IList&lt;SomeType&gt; Property { get { if(m_property == null) { m_property = new List&lt;SomeType&gt;(); } return m_property; } set { m_property = value; } } private IList&lt;SomeType&gt; m_property; } . and I suddenly doubting my already dubious C# knowledge. Thus I began a journey on to understand the actual use and various usage of patterns. (Don‚Äôt worry, I will also explain this example soon) . So what actually are Properties? . Before getting into why these exist, lets assume they didnt. Now say I had a data member in my class that was private but I needed to access it‚Äôs value in some other class, but not let it modify the value. For example . public class Bank { private int AccountBalance; } public class Me { var myBankAccount = new Bank(); var myMoney = myBankAccount.AccountBalance; } . Now if I cant directly access the AccountBalance property. If I make it public, although it might be fun for me, it might not be fun for the bank, when I could just do this . // The easy way of becoming a millionaire myBankAccount.AccountBalance = 1000000; . So what is the other solution? Ah yes, getters (and setters, their siblings). We could easily define a getter on this data member that will get us the value but not let modify it. Something like this: . public class Bank { private int AccountBalance; public int getAccountBalance() { return AccountBalance; } } public class Me { var myBankAccount = new Bank(); var myMoney = myBankAccount.getAccountBalance(); } . If you are used to working in Java with Eclipse, you know it has a functionality of auto generating getters and setters and I‚Äôm partly sure the creators of C# might have already loaded this in Visual Studio, but for people who didnt use it, this was a long and tedious methods to write this getters and setters. That‚Äôs why, C# creators created properties. . Properties provide an access mechanism for private data members . So even though you can essentially create data members using properties, that‚Äôs not their intended use. Essentially Properties provide a flexible mechanism to read, write or compute the value of a private field. They can be used as data members, but they are actually special methods called accessors, which as you guessed it, are useful for accessing data. . If you are not a fan of big words, this basically means, they are a shortcut for writing customized getter and setter methods. Thus, in a way, they indeed are syntactic sugar, without the harms? I am not going to bore you with the syntax of C# Properties, here is a good reference. . Now comes the fun part, the various usage patterns of Properties. The get and set aren‚Äôt just for show. You can customize them to implement various fun and useful patterns in your code, and here I‚Äôll show a few . Lazy Loading Values using Properties . Properties can help you implement a cache with lazy loading feature. For example . private int m_IncomeTax; public int IncomeTax { get { if(m_IncomeTax == null) { m_IncomeTax = AReallyLongComputationForTax(); } return m_IncomeTax; } } . This is the other primary usage of Properties, of course other than controlling access. . Future Proofing Code . Say you want to maintain the API of your class but the logic or calculation changes. To incorporate that without affecting your class API, you can change the setter code. . In terms of the above example, say in the computation for tax, they include a cess (YES! Tax on Tax!), you can change the getters like this, such that IncomeTax property gives you the total tax always. . // Old public int IncomeTax { get { return m_IncomeTax; } } // New public int IncomeTax { get { return m_IncomeTax + Cess; } } . Creating a Contract . Properties help you create a contract/API for a class. This way you can have a proper contract of accessing class members, which might be private or calculations on some private members. They are useful if you need some extra calculations on private members. . In general, the point is to separate implementation (the field) from API (the property). Later on you can, should you wish, put logic, logging etc in the property without breaking either source or binary compatibility - but more importantly you‚Äôre saying what your type is willing to do, rather than how it‚Äôs going to do it. More on this in this article . Returning Non Null Values using Properties . I promised I‚Äôll explain the code at the beginning of the section. For reference, this is the code . public class MyClass { public IList&lt;SomeType&gt; Property { get { if(m_property == null) { m_property = new List&lt;SomeType&gt;(); } return m_property; } set { m_property = value; } } private IList&lt;SomeType&gt; m_property; } . This code essentially checks whether a given member is null, and if it is null, it will populate the value first, and then return it. There is one great benefit of using this approach. Anything that consumes the value of this property need not have a null check, since this essentially ensures that you never get a null value and reduces the amount of code and checks you need to write, and don‚Äôt we all want to write less code? . In closing, I know properties seem like glorified setters/getters and all of the benefits mentioned above can also be done using setters and getters as well, as said above, they are just syntactic sugar. Learning how they can be used to control access rather than being used as public data members can help flesh out some nice code as well. . An honourable TypeScript Mention . Typescript itself has a similar method of implementing getters on private variables, which I remembered when I was reading up on properties. This looks quite similar to the C# Properties implementation and hence the mention here. . class MyClass { private _property; public get property() { return _property; } } var data = new MyClass(); var value = data.property; .",
            "url": "https://mitesh1612.github.io/blog/2020/08/19/c-sharp-properties",
            "relUrl": "/2020/08/19/c-sharp-properties",
            "date": " ‚Ä¢ Aug 19, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Conditional Probability and Families",
            "content": "So I was reading the book ‚ÄúData Science from Scratch‚Äù by Joel Grus. I came across this nice tricky problem in Conditional Probability mentioned in this book. Let‚Äôs take a look . A Quick Refresher on Conditional Probability . Well if you forgot the definition of conditional probability, here is a small refresher for you. Say there are two events E and F. The probability that E happens given that we know F happens is represented using . P(E‚à£F)P(E|F)P(E‚à£F) . Mathematically, . P(E‚à£F)=P(E,F)/P(F).P(E,F)P(E|F) = P(E,F)/P(F). P(E,F)P(E‚à£F)=P(E,F)/P(F).P(E,F) . is the probability of both E and F happening. . Well enough of a probability class, lets look at an interesting family now . The Family and The Unknown Children . Say there is a family with two unknown children. If we assume that: . Each child is equally likely to be a boy or a girl | The gender of the second child is independent of the first child. | . Then the event ‚Äúno girls‚Äù has probability 1/4, the event ‚Äúone girl, one boy‚Äù has probability 1/2, and the event ‚Äútwo girls‚Äù has probability 1/4. . Now here comes the interesting problem. ‚ÄúWhat is the probability of the event ‚Äòboth children are girls‚Äô (B) conditional on the event that ‚Äòthe older child is a girl (G)‚Äô?‚Äù . This aint a test, so here is how we can easily calculate this using conditional probability . P(B‚à£G)=P(B,G)/P(G)P(B|G) = P(B,G)/P(G)P(B‚à£G)=P(B,G)/P(G) . T event B and G (‚Äúboth children are girls and the older child is a girl‚Äù) is just the event B. (Once you know that both children are girls, it‚Äôs necessarily true that the older child is a girl). Thus, . P(B‚à£G)=P(B,G)/P(G)=P(B)/P(G)=1/2P(B|G) = P(B,G)/P(G) = P(B)/P(G) = 1/2P(B‚à£G)=P(B,G)/P(G)=P(B)/P(G)=1/2 . This is mostly intuitive. Now can you guess ‚ÄúWhat is the probability of the event ‚Äòboth children are girls‚Äô (B) conditional on the event that ‚Äòat least one of the children is a girl‚Äô (L)?‚Äù . Surprisingly, the answer to this question is different from the one before. Here is how . As before, the event B and L (‚Äúboth children are girls and at least one of the children is a girl‚Äù) is just the event B. This means we have: . P(B‚à£L)=P(B,L)/P(L)=P(B)/P(L)=1/3P(B|L) = P(B,L)/P(L) = P(B)/P(L) = 1/3P(B‚à£L)=P(B,L)/P(L)=P(B)/P(L)=1/3 . How can this be the case? Well, if all you know is that at least one of the children is a girl, then it is twice as likely that the family has one boy and one girl than that it has both girls. . Still don‚Äôt believe me? . Well if you are the doubting kind, we can write a simple Python code to simulate this experiment. . import enum, random class Kid(enum.Enum): BOY = 0 GIRL = 1 def random_kid() -&gt; Kid: return random.choice([Kid.BOY, Kid.GIRL]) both_girls = 0 older_girl = 0 either_girl = 0 random.seed(20200814) # Yep, this post&#39;s date for _ in range(10000): younger = random_kid() older = random_kid() if older == Kid.GIRL: older_girl += 1 if older == Kid.GIRL and younger == Kid.GIRL: both_girls += 1 if older == Kid.GIRL or younger == Kid.GIRL: either_girl += 1 print(&quot;P(both | older):&quot;, both_girls / older_girl) # 0.494 ~ 1/2 print(&quot;P(both | either): &quot;, both_girls / either_girl) # 0.322 ~ 1/3 . This indicates how the conditioning of an event affects its probability. . Weirdly, this problem reminds me a lot of the Monty Hall Problem. Hey if you have any explaination on how this can relate to Monty Hall, you can always @ me at my socials (linked in this blog at various locations!üòâ) and I‚Äôll probably try to figure out if there is any relation between these two (after I refresh my Probability Course üòã) .",
            "url": "https://mitesh1612.github.io/blog/2020/08/14/conditional-probability",
            "relUrl": "/2020/08/14/conditional-probability",
            "date": " ‚Ä¢ Aug 14, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Constructing a complex dictionary of base and derived class using the same code",
            "content": "Okay, really complex title aside, I‚Äôll try to explain the problem I had and the interesting way I found to solve it. This may not be the best or the most optimized way, but I really liked this solution and would like to share it. . Also, although I do prefer Python, this post is in C#, since that was the language I encountered this problem in. . So here is the problem. Say we have two C# Classes . public class BaseClass { public string SomeProperties { get; set; } } public class DerivedClass : BaseClass { public string SomeOtherProperties { get; set; } } . I wanted to construct a Dictionary of these classes like Dictionary&lt;string, BaseClass&gt; and Dictionary&lt;string, DerivedClass&gt; at two very different places. The construction of each dictionary element was not that trivial due to the inherent complexity of filling the properties for both the classes. Here is an example of how one of the dictionaries was being created: . // For the base class var map = new Dictionary&lt;string, BaseClass&gt;(); foreach(var someProperty in someList) { var baseElement = new BaseClass(someProperty); map[someProperty] = baseElement; } foreach(var dependency in dependencyList) { map[dependency.To] = map[dependency.From] } // For the derived class var map = new Dictionary&lt;string, DerivedClass&gt;(); foreach(var someProperty in someList) { // someOtherProperty comes from somewhere else var derivedElement = new DerivedClass(someProperty, someOtherProperty); map[someProperty] = derivedElement; } foreach(var dependency in dependencyList) { map[dependency.To] = map[dependency.From] } . As you can see, there is a lot of logic repeating since the properties that were created for the base class were also created for the derived class, but when we create the DerivedClass object, new properties were also to be added to those object. Both the objects differ in how they are constructed but the way the map is created is similar. I wanted a way to reuse these for loops instead of writing them for both BaseClass and DerivedClass and other classes that might inherit from BaseClass later. . My basic idea was to use a Template method like this. . public Dictionary&lt;string, &lt;T&gt;&gt; CreateDictionary(parameters) { while(someConditionOnParameters) { if(T is BaseClass) { // Base class object creation code } else if(T is DerivedClass) { // Derived class object creation code } // repeated dictionary creation code } } . The other problem that I encounter here in was the arguments to this method. When we create the BaseClass object, I require fewer properties but when I created DerivedClass object, I require more properties and hence the number and type of arguments couldn‚Äôt be fixed. Of course, I can set/pass them as null and ignore when not needed, but that didn‚Äôt feel like a tidy solution to me. Plus later on, when we derive a new class from BaseClass, again the signature of method changes which might break a few things here and there. . That‚Äôs when I was suggested the interesting solution to this problem, the one I am going to share now. We keep one function that creates this dictionary but rather than passing the parameters to create the objects, we pass a function that creates those objects for us. For example when we want to create the BaseClass dictionary, we can pass a function that creates the base class object and so on. This way this method can be extensible for any classes that derive from future as well. Here is a dummy code to show how that method might look like . public Dictionary&lt;string, BaseClass&gt; CreateDictionary(DataObject requiredData, Func&lt;Data, BaseClass&gt; objectCreator) { var map = new Dictionary&lt;string, BaseClass&gt;(); foreach(Data propertyValues in requiredData.data) { var element = objectCreator(Data); } foreach(var dependency in requiredData.dependencies) { map[dependency.To] = dependency.From; } } . Now when I want to create the base class dictionary, I can call it like: . var map = CreateDictionary(requiredData, x =&gt; { return new BaseClass(x.somePropertyValue); }); . Or if I want the derived class dictionary, like this: . var map = CreateDictionary(requiredData, x =&gt; { return new DerivedClass(x.SomePropertyValue, someOtherPropertyValue); }); . I really loved this solution, its nifty and useful and this didnt come to my mind easily. . Closing Thoughts . I know this is a really specific and weird problem to encounter, and some constraints of why this solution was used over other ways are not clear from the vague names and class designs (and possibly incomplete details) I provided. However, I really found the solution interesting and felt like sharing it. . You can always share your thoughts on this by @‚Äôing me on Twitter or LinkedIn (links are available in my author bio) or even this blog‚Äôs GitHub repo. .",
            "url": "https://mitesh1612.github.io/blog/2020/08/13/constructing-objects",
            "relUrl": "/2020/08/13/constructing-objects",
            "date": " ‚Ä¢ Aug 13, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Welcome to this blog",
            "content": "Welcome to this blog . Hey everyone, welcome to my blog. I finally took the leap and set up my blog, and after a lot of thinking, I finally decided to create a blog. . Why a blog? Well among a lot of other reasons, like not forgetting what I learn from time to time, and to keep track of my journey as a Software Development Engineer. The other huge reason is that I love to learn new things, research the ones I find interesting, and I plan to document and share my learnings via blog posts, which can be easily found and referred to later as well. I‚Äôll try to share things I learn about Software Development, my interests in Data Science and all the other random things I encounter. Hopefully, other people will also find these posts helpful, relevant or interesting. You can always share your views on my GitHub repo here (until I figure out adding comment sections to a static GitHub site üòâ) . Thanks for visiting this blog! . About Me . I‚Äôm Mitesh Shah, and I live in Hyderabad. I started my journey as a Software Engineer at Microsoft (where I currently work). I have a lot of interest in Data Science and Machine Learning and I love reading books or playing some games in my relaxing time. . Technical Details for this Blog . This blog is possible due to Gatsby JS with the wonderful theme Novela created by the Narative Team. Right now this site is hosted on GitHub pages using a CI from GitHub Actions . Update : 24-12-2020 . Since then, I have moved this blog to Fastpages. The links in this post are updated now. .",
            "url": "https://mitesh1612.github.io/blog/2020/08/12/welcome-to-this-blog",
            "relUrl": "/2020/08/12/welcome-to-this-blog",
            "date": " ‚Ä¢ Aug 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Hey there. I am the writer, Mitesh Shah, a Software Developer from India, casual gamer, gadget hoarder and learning more Software Development. Right now I work as a Software Engineer in Microsoft and love to read up on various topics like Data Science, Machine Learning, Backend Development in my free time. . I have been professionally writing code since 2019 (until then it was mostly academic) and while on my job, I have worked on writing scalable systems for Microsoft Azure. I get to learn a lot of things, things that I feel like sharing, or at least storing them for my own references later. So expect posts related to software development, writing maintainable code, but also posts related to Data Science, Machine Learning as well. . Tech you can talk to me about: . Backend Development using Flask, Node + Express, ASP.NET | Making Databases using MongoDB, MySQL | Frontend Development using Bootstrap, React (with Flux/Redux) | Creating cloud applications using Azure | Programming languages like C++, C#, Python, JavaScript / TypeScript | Machine Learning and the Maths behind it | . I like Machine Learning, and love understanding the why behind everything. To facilitate that, I often try to implement the common Machine Learning algorithms from scratch. . Feel free to connect with me on my socials: . &nbsp;&nbsp; &nbsp;&nbsp; .",
          "url": "https://mitesh1612.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://mitesh1612.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}